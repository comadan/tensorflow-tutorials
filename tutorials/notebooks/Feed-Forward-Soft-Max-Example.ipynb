{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Soft Max Model Example\n",
    "\n",
    "This notebook demonstrates a feed forward model using a soft-max output with cross-entropy cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_dataset = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Class\n",
    "\n",
    "We can use classes to encapsulate tensorflow models. The below skeleton shows one way of using classes with tensorflow.\n",
    "\n",
    "The Model class has methods, variables, and properties that capture both the graph and the tensorflow session\n",
    "\n",
    "#### Tensorflow Graph\n",
    "\n",
    "A tensorflow graph is a computational graph of different tensorflow operations. It defines the computation and how different operations and tensors relate, but it doesn't actually do the computation or store the values of the variables. All of that magic happens within the tensorflow session.\n",
    "\n",
    "#### Tensorflow Session\n",
    "\n",
    "A tensorflow session is the context where values for tensorflow variables are instantiated and computations are run. So if you are saving a model's weights, you are actually saving the weights of the tensorflow session. If you are loading a model's weights, you need to load them into a session. When variables are initialized, that has to happen within a session. In a way, the graph is stateless. State is stored in sessions. The session also takes care of running computations, so if you are running training, those need to be run in the session.\n",
    "\n",
    "A session is instantiated with a graph, typically the current default graph. A session is only able to run computations on the graph that is tied to the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DeepLearningModel():\n",
    "    def __init__():\n",
    "        return\n",
    "    \n",
    "    def gen_uniform_random_weights(self, k_out, k_in, scale, dtype=np.float32):\n",
    "        \"\"\"\n",
    "        Returns weights of shape (k_in, k_out) initialized between [-scale, scale]\n",
    "        \"\"\"\n",
    "        return ((np.random.rand(k_in, k_out) * 2 - 1) * scale).astype(dtype)\n",
    "\n",
    "    def gen_random_weights_tanh(self, k_out, k_in, dtype=np.float32):\n",
    "        scale = (6. / (k_in + k_out)) ** .5\n",
    "        return self.gen_uniform_random_weights(k_out, k_in, scale, dtype=dtype)\n",
    "\n",
    "    def gen_random_weights_sigmoid(self, k_out, k_in, dtype=np.float32):\n",
    "        scale = 4. * (6. / (k_in + k_out)) ** .5\n",
    "        return self.gen_uniform_random_weights(k_out, k_in, scale, dtype=dtype)\n",
    "\n",
    "    def gen_random_weights_reLu(self, k_out, k_in, dtype=np.float32):\n",
    "        scale = (2. / (k_in + k_out)) ** .5\n",
    "        return self.gen_uniform_random_weights(k_out, k_in, scale, dtype=dtype)\n",
    "\n",
    "    def gen_biases(self, k, dtype=np.float32):\n",
    "        \"\"\"\n",
    "        Initialize biases as zero.\n",
    "        \"\"\"\n",
    "        return np.zeros((k, ), dtype=dtype)\n",
    "    \n",
    "    def clip_gradient(self, grad, magnitude=1.0):\n",
    "        \"\"\"returns a clipped gradient, where it is between [-magnitude and magnitude]\"\"\"\n",
    "        magnitude = abs(magnitude)\n",
    "        return tf.maximum(tf.minimum(grad, magnitude), - magnitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeedForwardSoftMaxModel(DeepLearningModel):\n",
    "    \"\"\"\n",
    "    Tutorial Model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_layers, k_hidden, k_input, k_softmax, activation_function=tf.nn.tanh):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            num_layers: number of hidden layers\n",
    "            k_hidden: number of units in the hidden layers\n",
    "            k_input: dimensionality of the input\n",
    "            k_softmax: dimensionality of the output layer\n",
    "        \"\"\"\n",
    "        self._graph = None\n",
    "        self._session = None\n",
    "        self.num_layers = num_layers\n",
    "        self.k_hidden = k_hidden\n",
    "        self.k_input = k_input\n",
    "        self.k_softmax = k_softmax\n",
    "        self.activation_function = activation_function\n",
    "        \n",
    "        self._merged_training_summary = None\n",
    "        self._merged_validation_summary = None\n",
    "    \n",
    "    \n",
    "    def load_model(self, model_filename):\n",
    "        with self.graph.as_default():\n",
    "            model_saver = tf.train.Saver()\n",
    "        \n",
    "        self._session = tf.Session(graph=self.graph)\n",
    "        model_saver.restore(self._session, model_filename)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def save_model(self, model_filename):\n",
    "        with self.graph.as_default():\n",
    "            model_saver = tf.train.Saver()\n",
    "            \n",
    "        model_saver.save(self.session, model_filename)\n",
    "        \n",
    "    def create_graph(self):\n",
    "        self.W = {}\n",
    "        self.b = {}\n",
    "        self.Z = {}\n",
    "        self.A = {}\n",
    "        self.A_dropped_out = {}\n",
    "        self.new_W_value = {}\n",
    "        self.new_b_value = {}\n",
    "        self.assign_new_W = {}\n",
    "        self.assign_new_b = {}\n",
    "                \n",
    "        self._graph = tf.Graph()\n",
    "        with self._graph.as_default():\n",
    "            with tf.name_scope(\"inputs\"):                \n",
    "                self.learning_rate = tf.placeholder(tf.float32, shape=(), name=\"learning_rate\")\n",
    "                self.adam_beta1 = tf.placeholder(tf.float32, shape=(), name=\"adam_beta1\")\n",
    "                self.adam_beta2 = tf.placeholder(tf.float32, shape=(), name=\"adam_beta2\")\n",
    "                self.adam_epsilon = tf.placeholder(tf.float32, shape=(), name=\"adam_epsilon\")\n",
    "                self.input_dropout_keep_prob = tf.placeholder(tf.float32, shape=(), name=\"input_dropout_keep_prob\")\n",
    "                self.hidden_dropout_keep_prob = tf.placeholder(tf.float32, shape=(), name=\"hidden_dropout_keep_prob\")\n",
    "                \n",
    "                self.X = tf.placeholder(tf.float32, name=\"X\")\n",
    "                self.Y = tf.placeholder(tf.int32, shape=(None,), name=\"Y\")\n",
    "                self.A[0] = tf.identity(self.X, name=\"A_0\")\n",
    "                self.A_dropped_out[0] = tf.nn.dropout(self.A[0], self.input_dropout_keep_prob, name=\"A_droppedout_0\")\n",
    "            \n",
    "            with tf.name_scope(\"hidden_layers\"):\n",
    "                for layer in range(1, self.num_layers + 1):\n",
    "                    if layer == 1:\n",
    "                        k_in = self.k_input\n",
    "                    else:\n",
    "                        k_in = self.k_hidden\n",
    "\n",
    "                    self.W[(layer, layer - 1)] = tf.Variable(self.gen_random_weights_tanh(self.k_hidden, k_in), dtype=tf.float32, name=\"W_%i_%i\" % (layer, layer - 1))\n",
    "                    self.b[layer] = tf.Variable(self.gen_biases(self.k_hidden), dtype=tf.float32, name=\"b_%i\" % (layer, ))\n",
    "                    self.Z[layer] = tf.add(tf.matmul(self.A_dropped_out[layer - 1], self.W[(layer, layer - 1)]), self.b[layer], name=\"Z_%i\" % (layer, ))\n",
    "                    self.A[layer] = self.activation_function(self.Z[layer], name=\"A_%i\" % (layer, ))\n",
    "                    self.A_dropped_out[layer] = tf.nn.dropout(self.A[layer], self.hidden_dropout_keep_prob, name=\"A_droppedout_%i\" % (layer, ))\n",
    "                        \n",
    "            with tf.name_scope(\"softmax\"):\n",
    "                layer = \"softmax\"\n",
    "                self.W[(layer, self.num_layers)] = tf.Variable(self.gen_random_weights_tanh(self.k_softmax, self.k_hidden), dtype=tf.float32, name=\"W_%s_%i\" % (layer, self.num_layers))\n",
    "                self.b[layer] = tf.Variable(self.gen_biases(self.k_softmax), dtype=tf.float32, name=\"b_%s\" % (layer, ))\n",
    "                self.Z[layer] = tf.add(tf.matmul(self.A[self.num_layers], self.W[(layer, self.num_layers)]), self.b[layer], name=\"Z_%s\" % (layer, ))\n",
    "                self.softmax = tf.nn.softmax(self.Z[layer], name=\"soft_max\")\n",
    "            \n",
    "            with tf.name_scope(\"parameter_assignment\"):\n",
    "                for layer_pair in self.W.keys():\n",
    "                    self.new_W_value[layer_pair] = tf.placeholder(tf.float32)\n",
    "                    self.assign_new_W[layer_pair] = self.W[layer_pair].assign(self.new_W_value[layer_pair])\n",
    "                for layer in self.b.keys():\n",
    "                    self.new_b_value[layer] = tf.placeholder(tf.float32)\n",
    "                    self.assign_new_b[layer] = self.b[layer].assign(self.new_b_value[layer])\n",
    "\n",
    "            \n",
    "            with tf.name_scope(\"cost\"):\n",
    "                with tf.name_scope(\"regularization\"):\n",
    "                    self.L2_reg = tf.placeholder(tf.float32, name=\"L2_reg\")\n",
    "                    for layer in range(1, self.num_layers + 1):\n",
    "                        if layer == 1:\n",
    "                            k_in = self.k_input\n",
    "                            self.cost_L2 = self.L2_reg * tf.reduce_mean(tf.square(self.W[(layer, layer - 1)]))\n",
    "                        else:\n",
    "                            k_in = self.k_hidden\n",
    "                            self.cost_L2 = self.cost_L2 + self.L2_reg * tf.reduce_mean(tf.square(self.W[(layer, layer - 1)]))\n",
    "                    self.cost_L2 = tf.identity(self.cost_L2, 'cost_L2_regularization')\n",
    "                \n",
    "                with tf.name_scope(\"error\"):\n",
    "                    self.cross_entropy_error = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.Y, logits=self.Z[\"softmax\"]))\n",
    "                self.total_cost = tf.add(self.cost_L2, self.cross_entropy_error)\n",
    "            \n",
    "            with tf.name_scope(\"optimization\"):\n",
    "                self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate, beta1=self.adam_beta1, beta2=self.adam_beta2, epsilon=self.adam_epsilon)\n",
    "                self.grads_and_vars = self.optimizer.compute_gradients(self.total_cost)                    \n",
    "                self.clipped_grads_and_vars = [(self.clip_gradient(gv[0]), gv[1]) for gv in self.grads_and_vars]\n",
    "                self.update_op = self.optimizer.apply_gradients(self.clipped_grads_and_vars)\n",
    "                \n",
    "            self.init_op = tf.global_variables_initializer()\n",
    "        return\n",
    "            \n",
    "    def create_tensorboard_summaries(self):\n",
    "        with self.graph.as_default():\n",
    "            with tf.name_scope(\"summaries\"):\n",
    "                tf.summary.scalar('cross_entropy_error', self.cross_entropy_error, collections=['train'])\n",
    "                tf.summary.scalar('cost_L2_regularization', self.cost_L2, collections=['train'])\n",
    "\n",
    "                tf.summary.scalar('cross_entropy_error_validation', self.cross_entropy_error, collections=['validation'])\n",
    "\n",
    "                for layer in range(1, self.num_layers + 1):\n",
    "                    tf.summary.histogram(\"W_%i_%i\" % (layer, layer - 1), self.W[(layer, layer - 1)], collections=['train'])\n",
    "                    tf.summary.histogram(\"b_%i\" % (layer, ), self.b[layer], collections=['train'])\n",
    "                for layer in [\"softmax\"]:\n",
    "                    tf.summary.histogram(\"W_%s_%i\" % (layer, self.num_layers), self.W[(layer, self.num_layers)], collections=['train'])\n",
    "                    tf.summary.histogram(\"b_%s\" % (layer, ), self.b[layer], collections=['train'])\n",
    "\n",
    "                self._merged_training_summary = tf.summary.merge_all(key='train')\n",
    "                self._merged_validation_summary = tf.summary.merge_all(key='validation')\n",
    "        return\n",
    "    \n",
    "    def create_tensorboard_writer(self, tensorboard_directory=\"./\"):\n",
    "        \"\"\"I'm not sure if this needs to be within a session\"\"\"\n",
    "        self._tensorboard_writer = tf.summary.FileWriter(tensorboard_directory, graph=self.graph)\n",
    "    \n",
    "    def write_graph(self):\n",
    "        self.tensorboard_writer.add_graph(self.graph)\n",
    "        return\n",
    "    \n",
    "    def init_model(self, adam_beta1=0.9, adam_beta2=0.999):\n",
    "        self.session.run(self.init_op, \n",
    "                         feed_dict={\n",
    "                             self.adam_beta1: adam_beta1,\n",
    "                             self.adam_beta2: adam_beta2\n",
    "                         })\n",
    "    \n",
    "    def assign_W(self, layer, value):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            layer: typically a tuple indicating the output and input layer (output_layer, input_layer), e.g. (2, 1) to indicate the connection from 2 to 1.\n",
    "        \"\"\"\n",
    "        self.session.run(self.assign_new_W[layer], \n",
    "                         feed_dict={self.new_W_value[layer]: value})\n",
    "    \n",
    "    def assign_b(self, layer, value):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            layer: typically a tuple indicating the output and input layer (output_layer, input_layer), e.g. (2, 1) to indicate the connection from 2 to 1.\n",
    "        \"\"\"\n",
    "        self.session.run(self.assign_new_b[layer], \n",
    "                         feed_dict={self.new_b_value[layer]: value})\n",
    "    \n",
    "    def train_model(self, X, Y, learning_rate=1e-2, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, \n",
    "                    input_dropout_keep_prob=1.0, hidden_dropout_keep_prob=1.0,\n",
    "                    L2_reg=1e-4):\n",
    "        \"\"\"\n",
    "        learning_rate: A Tensor or a floating point value. The learning rate.\n",
    "        beta1: A float value or a constant float tensor. The exponential decay rate for the 1st moment estimates.\n",
    "        beta2: A float value or a constant float tensor. The exponential decay rate for the 2nd moment estimates.\n",
    "        epsilon: A small constant for numerical stability. This epsilon is \"epsilon hat\" in the Kingma and Ba paper (in the formula just before Section 2.1), not the epsilon in Algorithm 1 of the paper.\n",
    "        \"\"\"\n",
    "        self.session.run(self.update_op,\n",
    "                         feed_dict = {\n",
    "                             self.X: X,\n",
    "                             self.Y: Y,\n",
    "                             self.learning_rate: learning_rate,\n",
    "                             self.adam_beta1: adam_beta1,\n",
    "                             self.adam_beta2: adam_beta2,\n",
    "                             self.adam_epsilon: adam_epsilon,\n",
    "                             self.input_dropout_keep_prob: input_dropout_keep_prob,\n",
    "                             self.hidden_dropout_keep_prob: hidden_dropout_keep_prob,\n",
    "                             self.L2_reg: L2_reg\n",
    "                         })\n",
    "        return\n",
    "    \n",
    "    def write_validation_summary(self, X, Y, step,\n",
    "                                 L2_reg=1e-4):\n",
    "        summary = self.session.run(self.merged_validation_summary,\n",
    "                                   feed_dict = {\n",
    "                                       self.X: X,\n",
    "                                       self.Y: Y,\n",
    "                                       self.input_dropout_keep_prob: 1.0,\n",
    "                                       self.hidden_dropout_keep_prob: 1.0,\n",
    "                                       self.L2_reg: L2_reg\n",
    "                                   })\n",
    "        self.tensorboard_writer.add_summary(summary, step)\n",
    "        return\n",
    "    \n",
    "    def write_training_summary(self, X, Y, step,\n",
    "                               L2_reg=1e-4):\n",
    "        summary = self.session.run(self.merged_training_summary,\n",
    "                                   feed_dict = {\n",
    "                                       self.X: X,\n",
    "                                       self.Y: Y,\n",
    "                                       self.input_dropout_keep_prob: 1.0,\n",
    "                                       self.hidden_dropout_keep_prob: 1.0,\n",
    "                                       self.L2_reg: L2_reg\n",
    "                                   })\n",
    "        self.tensorboard_writer.add_summary(summary, step)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def graph(self):\n",
    "        if self._graph is None:\n",
    "            self.create_graph()\n",
    "        return self._graph\n",
    "    \n",
    "    @property\n",
    "    def session(self):\n",
    "        if self._session is None:\n",
    "            self._session = tf.Session(graph=self.graph)\n",
    "        return self._session\n",
    "    \n",
    "    @property\n",
    "    def merged_training_summary(self):\n",
    "        if self._merged_training_summary is None:\n",
    "            self.create_tensorboard_summaries()\n",
    "        return self._merged_training_summary\n",
    "    \n",
    "    @property\n",
    "    def merged_validation_summary(self):\n",
    "        if self._merged_validation_summary is None:\n",
    "            self.create_tensorboard_summaries()\n",
    "        return self._merged_validation_summary\n",
    "    \n",
    "    @property\n",
    "    def tensorboard_writer(self):\n",
    "        if self._tensorboard_writer is None:\n",
    "            self.create_tensorboard_writer()\n",
    "        return self._tensorboard_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "k_hidden = 10\n",
    "k_input = 4\n",
    "k_softmax = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a model instance with 2 hidden layers and 10 hidden units.\n",
    "\n",
    "model_a = FeedForwardSoftMaxModel(num_layers, k_hidden, k_input, k_softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lazy Properties\n",
    "\n",
    "The class doesn't actually create the graph or session until the graph and session properties are called. The @property decorator functions above are used to create a graph or session if none exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a._graph is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a._session is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x115ff2490>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x114f4b410>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 0): <tf.Variable 'hidden_layers/W_1_0:0' shape=(4, 10) dtype=float32_ref>,\n",
       " (2,\n",
       "  1): <tf.Variable 'hidden_layers/W_2_1:0' shape=(10, 10) dtype=float32_ref>,\n",
       " ('softmax',\n",
       "  2): <tf.Variable 'softmax/W_softmax_2:0' shape=(10, 3) dtype=float32_ref>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <tf.Variable 'hidden_layers/b_1:0' shape=(10,) dtype=float32_ref>,\n",
       " 2: <tf.Variable 'hidden_layers/b_2:0' shape=(10,) dtype=float32_ref>,\n",
       " 'softmax': <tf.Variable 'softmax/b_softmax:0' shape=(3,) dtype=float32_ref>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'summaries/Merge/MergeSummary:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.merged_training_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'summaries/Merge_1/MergeSummary:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.merged_validation_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'summaries/Merge/MergeSummary:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.merged_training_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'summaries/Merge_1/MergeSummary:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.merged_validation_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_a.init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1,\n",
       "  0): array([[-0.53383142, -0.26800293,  0.30587319,  0.41528845,  0.53037804,\n",
       "          0.54393131,  0.25059569,  0.3829636 ,  0.52883643,  0.22119667],\n",
       "        [ 0.43764803, -0.18851139,  0.08263879,  0.5383625 ,  0.39127269,\n",
       "         -0.2205787 , -0.25064543,  0.48002577, -0.52354157, -0.05719423],\n",
       "        [ 0.32512787, -0.29318693, -0.02891652, -0.5973413 , -0.50016761,\n",
       "         -0.18938035,  0.38525584,  0.39774391,  0.615116  , -0.43968138],\n",
       "        [-0.64172977, -0.60338551, -0.01295396, -0.48267376, -0.33937457,\n",
       "          0.54366893,  0.39634818,  0.49564573, -0.58831275,  0.43020582]], dtype=float32),\n",
       " (2, 1): array([[  4.59960073e-01,  -1.37809038e-01,  -2.03138635e-01,\n",
       "           1.28261879e-01,  -1.21349864e-01,   5.51811745e-03,\n",
       "           1.35973215e-01,   1.35233074e-01,   9.69059393e-02,\n",
       "           5.28214693e-01],\n",
       "        [  2.33344719e-01,  -4.80115898e-02,   1.37993753e-01,\n",
       "          -3.29962254e-01,  -2.87121356e-01,  -2.33356997e-01,\n",
       "          -3.46505344e-02,   4.61643726e-01,  -2.49410629e-01,\n",
       "           5.44065058e-01],\n",
       "        [ -4.87405568e-01,   4.38637465e-01,   1.20349050e-01,\n",
       "          -3.10226917e-01,  -2.80846685e-01,  -4.86697197e-01,\n",
       "          -1.40868187e-01,   2.96673566e-01,   1.77821770e-01,\n",
       "          -1.90407932e-01],\n",
       "        [  3.23664159e-01,  -7.38914534e-02,  -2.18577638e-01,\n",
       "           8.21232647e-02,   4.75254446e-01,   4.03603241e-02,\n",
       "           4.93323922e-01,   4.00475979e-01,   2.36793280e-01,\n",
       "          -2.68262744e-01],\n",
       "        [ -6.98405951e-02,  -1.34549037e-01,   2.51914859e-01,\n",
       "          -8.91023595e-03,   4.48524296e-01,  -5.06057203e-01,\n",
       "          -2.19090626e-01,  -4.85921949e-01,  -4.70843673e-01,\n",
       "           4.93726432e-01],\n",
       "        [ -6.31286502e-02,   2.46306628e-01,  -3.03264499e-01,\n",
       "          -2.60790437e-01,  -3.02504003e-01,   2.56185859e-01,\n",
       "          -5.24350047e-01,  -4.65991616e-01,   4.07129884e-01,\n",
       "           1.11126080e-01],\n",
       "        [  6.56054094e-02,   9.56166163e-02,   1.68132514e-01,\n",
       "          -1.87888891e-01,   2.02404246e-01,   2.79812396e-01,\n",
       "          -1.51711583e-01,  -8.90455171e-02,  -2.21317500e-01,\n",
       "           8.20880234e-02],\n",
       "        [ -7.78727420e-03,   1.84463814e-01,  -1.04911909e-01,\n",
       "          -4.83803332e-01,  -2.31420547e-01,  -3.13591450e-01,\n",
       "          -4.57272828e-01,   4.04356480e-01,   2.66739196e-04,\n",
       "          -4.68548477e-01],\n",
       "        [ -4.91405815e-01,  -1.26679718e-01,   4.29969639e-01,\n",
       "           1.65861398e-01,  -6.76388219e-02,  -1.07457004e-01,\n",
       "          -5.01178384e-01,  -3.67394924e-01,  -9.59351882e-02,\n",
       "           4.24712300e-01],\n",
       "        [  1.54906169e-01,   3.98472637e-01,   3.18168886e-02,\n",
       "          -2.42658764e-01,   4.43276733e-01,   3.40184122e-01,\n",
       "           8.19061622e-02,  -3.93683821e-01,  -7.28835091e-02,\n",
       "          -1.74904048e-01]], dtype=float32),\n",
       " ('softmax', 2): array([[-0.08011644,  0.58593774,  0.55253184],\n",
       "        [-0.19731884,  0.04922017, -0.14093259],\n",
       "        [-0.39247882,  0.39264911, -0.21645893],\n",
       "        [ 0.09926299,  0.35876557, -0.32410195],\n",
       "        [-0.11836482, -0.36420357, -0.13226473],\n",
       "        [ 0.30506042,  0.61776197, -0.13538907],\n",
       "        [ 0.20973095,  0.01963617, -0.36406228],\n",
       "        [-0.13945805, -0.67443508,  0.31141901],\n",
       "        [ 0.33934736, -0.49604774, -0.3037287 ],\n",
       "        [ 0.4302294 , -0.10262287, -0.2231593 ]], dtype=float32)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.session.run(model_a.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " 2: array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " 'softmax': array([ 0.,  0.,  0.], dtype=float32)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.session.run(model_a.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_a.create_tensorboard_writer(\"./tensorboard/model_a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_a.write_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Operations\n",
    "\n",
    "The class adds some convenience functions for assigning weights. Tensorflow can only assign values to tensor variables using assignment operations, and a combination of a placeholder and assignment operation are used to allow the assignment through a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 0): <tf.Variable 'hidden_layers/W_1_0:0' shape=(4, 10) dtype=float32_ref>,\n",
       " (2,\n",
       "  1): <tf.Variable 'hidden_layers/W_2_1:0' shape=(10, 10) dtype=float32_ref>,\n",
       " ('softmax',\n",
       "  2): <tf.Variable 'softmax/W_softmax_2:0' shape=(10, 3) dtype=float32_ref>}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0), ('softmax', 2), (2, 1)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.W.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1,\n",
       "  0): <tf.Tensor 'parameter_assignment/Placeholder:0' shape=<unknown> dtype=float32>,\n",
       " (2,\n",
       "  1): <tf.Tensor 'parameter_assignment/Placeholder_2:0' shape=<unknown> dtype=float32>,\n",
       " ('softmax',\n",
       "  2): <tf.Tensor 'parameter_assignment/Placeholder_1:0' shape=<unknown> dtype=float32>}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.new_W_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_a.assign_W((1, 0), np.ones((4, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_a.assign_W(('softmax', 2), np.ones((10, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_a.assign_W((2, 1), np.ones((10, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 0): array([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]], dtype=float32),\n",
       " (2, 1): array([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]], dtype=float32),\n",
       " ('softmax', 2): array([[ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.]], dtype=float32)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.session.run(model_a.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <tf.Variable 'hidden_layers/b_1:0' shape=(10,) dtype=float32_ref>,\n",
       " 2: <tf.Variable 'hidden_layers/b_2:0' shape=(10,) dtype=float32_ref>,\n",
       " 'softmax': <tf.Variable 'softmax/b_softmax:0' shape=(3,) dtype=float32_ref>}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <tf.Tensor 'parameter_assignment/Placeholder_3:0' shape=<unknown> dtype=float32>,\n",
       " 2: <tf.Tensor 'parameter_assignment/Placeholder_4:0' shape=<unknown> dtype=float32>,\n",
       " 'softmax': <tf.Tensor 'parameter_assignment/Placeholder_5:0' shape=<unknown> dtype=float32>}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.new_b_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_a.assign_b(1, np.ones((10,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_a.assign_b('softmax', np.ones((3, )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_a.assign_b(2, np.ones((10,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32),\n",
       " 2: array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32),\n",
       " 'softmax': array([ 1.,  1.,  1.], dtype=float32)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a.session.run(model_a.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_a.save_model(\"./saved_model/test_saved_model.cpkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the saved model into a second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_b = FeedForwardSoftMaxModel(num_layers, k_hidden, k_input, k_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_model/test_saved_model.cpkt\n"
     ]
    }
   ],
   "source": [
    "model_b.load_model(\"./saved_model/test_saved_model.cpkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 0): <tf.Variable 'hidden_layers/W_1_0:0' shape=(4, 10) dtype=float32_ref>,\n",
       " (2,\n",
       "  1): <tf.Variable 'hidden_layers/W_2_1:0' shape=(10, 10) dtype=float32_ref>,\n",
       " ('softmax',\n",
       "  2): <tf.Variable 'softmax/W_softmax_2:0' shape=(10, 3) dtype=float32_ref>}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 0): array([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]], dtype=float32),\n",
       " (2, 1): array([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]], dtype=float32),\n",
       " ('softmax', 2): array([[ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.]], dtype=float32)}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.session.run(model_b.W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_c = FeedForwardSoftMaxModel(num_layers, k_hidden, k_input, k_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_c.init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " 2: array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " 'softmax': array([ 0.,  0.,  0.], dtype=float32)}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_c.session.run(model_c.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1,\n",
       "  0): array([[ 0.28000289,  0.23105153, -0.33771443, -0.31311759,  0.53268135,\n",
       "          0.25044283,  0.58518004, -0.59958947, -0.60120815, -0.34895009],\n",
       "        [ 0.2810252 , -0.17252007, -0.61412835, -0.34781274,  0.37581402,\n",
       "         -0.59056562,  0.46723518,  0.33566508, -0.43742433, -0.40618837],\n",
       "        [ 0.22088052,  0.59920073,  0.07000663, -0.03320396,  0.10626927,\n",
       "         -0.11497881, -0.29285419, -0.43204159,  0.1853268 ,  0.55036724],\n",
       "        [ 0.01022691,  0.60928577,  0.62619817, -0.48394573, -0.46712208,\n",
       "         -0.22698082, -0.36513788,  0.37369412,  0.22148553,  0.13890925]], dtype=float32),\n",
       " (2,\n",
       "  1): array([[ 0.3068825 , -0.2885817 ,  0.22892857,  0.31222558,  0.22021452,\n",
       "          0.30423072,  0.48374948, -0.36762428, -0.52571899,  0.33897048],\n",
       "        [-0.47151569, -0.47213507,  0.11783093, -0.11754851,  0.41255018,\n",
       "          0.31946424, -0.21307269, -0.03902682, -0.45915243, -0.38658398],\n",
       "        [-0.28733075, -0.39249817,  0.05153377,  0.11287121,  0.50044334,\n",
       "         -0.28615794,  0.14874488, -0.00615952, -0.14321105, -0.01791534],\n",
       "        [ 0.05987751, -0.15199803, -0.04624595,  0.05347144,  0.39551952,\n",
       "          0.43326238, -0.24120498,  0.21301402,  0.19579479, -0.35638869],\n",
       "        [-0.4585928 ,  0.44404235,  0.12979214, -0.23042198, -0.2316836 ,\n",
       "         -0.3038097 ,  0.14449474, -0.33270141,  0.51724613,  0.49410689],\n",
       "        [-0.36916241,  0.47267473,  0.2733551 ,  0.00867516, -0.50107408,\n",
       "         -0.1363627 , -0.00132931,  0.05824312, -0.27131426, -0.44271395],\n",
       "        [-0.33411556, -0.17892179, -0.41827971,  0.10860661, -0.24272281,\n",
       "          0.47978529, -0.43905935,  0.22502348,  0.10832337, -0.54267049],\n",
       "        [-0.17704614,  0.28094804, -0.30085301, -0.47810945, -0.14340024,\n",
       "         -0.42773581, -0.5412311 , -0.34142211,  0.27541974, -0.0186154 ],\n",
       "        [ 0.16036561,  0.33061692, -0.22956701, -0.41907367, -0.3058961 ,\n",
       "          0.19925694,  0.12682125, -0.04402824, -0.22062843,  0.12117522],\n",
       "        [ 0.29049838, -0.4243364 ,  0.12643108,  0.32964197,  0.37732849,\n",
       "          0.29025224,  0.3405447 ,  0.14258194, -0.26368839, -0.01283801]], dtype=float32),\n",
       " ('softmax', 2): array([[-0.39622128,  0.34444293, -0.61575276],\n",
       "        [ 0.48451227,  0.25628543, -0.30300149],\n",
       "        [ 0.30676347,  0.16897969,  0.364838  ],\n",
       "        [-0.62237853,  0.37582159, -0.41268918],\n",
       "        [-0.3511422 ,  0.12719251, -0.03687367],\n",
       "        [-0.37650093,  0.5350796 ,  0.31190565],\n",
       "        [ 0.13341649,  0.10812241, -0.04455149],\n",
       "        [-0.51707536, -0.4698416 , -0.59595948],\n",
       "        [ 0.62068844,  0.56558758, -0.38354883],\n",
       "        [-0.3183783 ,  0.2903477 , -0.10690694]], dtype=float32)}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_c.session.run(model_c.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5.4,  3.7,  1.5,  0.2],\n",
       "       [ 4.8,  3.4,  1.6,  0.2],\n",
       "       [ 4.8,  3. ,  1.4,  0.1],\n",
       "       [ 4.3,  3. ,  1.1,  0.1],\n",
       "       [ 5.8,  4. ,  1.2,  0.2],\n",
       "       [ 5.7,  4.4,  1.5,  0.4],\n",
       "       [ 5.4,  3.9,  1.3,  0.4],\n",
       "       [ 5.1,  3.5,  1.4,  0.3],\n",
       "       [ 5.7,  3.8,  1.7,  0.3],\n",
       "       [ 5.1,  3.8,  1.5,  0.3],\n",
       "       [ 5.4,  3.4,  1.7,  0.2],\n",
       "       [ 5.1,  3.7,  1.5,  0.4],\n",
       "       [ 4.6,  3.6,  1. ,  0.2],\n",
       "       [ 5.1,  3.3,  1.7,  0.5],\n",
       "       [ 4.8,  3.4,  1.9,  0.2],\n",
       "       [ 5. ,  3. ,  1.6,  0.2],\n",
       "       [ 5. ,  3.4,  1.6,  0.4],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 5.2,  3.4,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.6,  0.2],\n",
       "       [ 4.8,  3.1,  1.6,  0.2],\n",
       "       [ 5.4,  3.4,  1.5,  0.4],\n",
       "       [ 5.2,  4.1,  1.5,  0.1],\n",
       "       [ 5.5,  4.2,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5. ,  3.2,  1.2,  0.2],\n",
       "       [ 5.5,  3.5,  1.3,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 4.4,  3. ,  1.3,  0.2],\n",
       "       [ 5.1,  3.4,  1.5,  0.2],\n",
       "       [ 5. ,  3.5,  1.3,  0.3],\n",
       "       [ 4.5,  2.3,  1.3,  0.3],\n",
       "       [ 4.4,  3.2,  1.3,  0.2],\n",
       "       [ 5. ,  3.5,  1.6,  0.6],\n",
       "       [ 5.1,  3.8,  1.9,  0.4],\n",
       "       [ 4.8,  3. ,  1.4,  0.3],\n",
       "       [ 5.1,  3.8,  1.6,  0.2],\n",
       "       [ 4.6,  3.2,  1.4,  0.2],\n",
       "       [ 5.3,  3.7,  1.5,  0.2],\n",
       "       [ 5. ,  3.3,  1.4,  0.2],\n",
       "       [ 7. ,  3.2,  4.7,  1.4],\n",
       "       [ 6.4,  3.2,  4.5,  1.5],\n",
       "       [ 6.9,  3.1,  4.9,  1.5],\n",
       "       [ 5.5,  2.3,  4. ,  1.3],\n",
       "       [ 6.5,  2.8,  4.6,  1.5],\n",
       "       [ 5.7,  2.8,  4.5,  1.3],\n",
       "       [ 6.3,  3.3,  4.7,  1.6],\n",
       "       [ 4.9,  2.4,  3.3,  1. ],\n",
       "       [ 6.6,  2.9,  4.6,  1.3],\n",
       "       [ 5.2,  2.7,  3.9,  1.4],\n",
       "       [ 5. ,  2. ,  3.5,  1. ],\n",
       "       [ 5.9,  3. ,  4.2,  1.5],\n",
       "       [ 6. ,  2.2,  4. ,  1. ],\n",
       "       [ 6.1,  2.9,  4.7,  1.4],\n",
       "       [ 5.6,  2.9,  3.6,  1.3],\n",
       "       [ 6.7,  3.1,  4.4,  1.4],\n",
       "       [ 5.6,  3. ,  4.5,  1.5],\n",
       "       [ 5.8,  2.7,  4.1,  1. ],\n",
       "       [ 6.2,  2.2,  4.5,  1.5],\n",
       "       [ 5.6,  2.5,  3.9,  1.1],\n",
       "       [ 5.9,  3.2,  4.8,  1.8],\n",
       "       [ 6.1,  2.8,  4. ,  1.3],\n",
       "       [ 6.3,  2.5,  4.9,  1.5],\n",
       "       [ 6.1,  2.8,  4.7,  1.2],\n",
       "       [ 6.4,  2.9,  4.3,  1.3],\n",
       "       [ 6.6,  3. ,  4.4,  1.4],\n",
       "       [ 6.8,  2.8,  4.8,  1.4],\n",
       "       [ 6.7,  3. ,  5. ,  1.7],\n",
       "       [ 6. ,  2.9,  4.5,  1.5],\n",
       "       [ 5.7,  2.6,  3.5,  1. ],\n",
       "       [ 5.5,  2.4,  3.8,  1.1],\n",
       "       [ 5.5,  2.4,  3.7,  1. ],\n",
       "       [ 5.8,  2.7,  3.9,  1.2],\n",
       "       [ 6. ,  2.7,  5.1,  1.6],\n",
       "       [ 5.4,  3. ,  4.5,  1.5],\n",
       "       [ 6. ,  3.4,  4.5,  1.6],\n",
       "       [ 6.7,  3.1,  4.7,  1.5],\n",
       "       [ 6.3,  2.3,  4.4,  1.3],\n",
       "       [ 5.6,  3. ,  4.1,  1.3],\n",
       "       [ 5.5,  2.5,  4. ,  1.3],\n",
       "       [ 5.5,  2.6,  4.4,  1.2],\n",
       "       [ 6.1,  3. ,  4.6,  1.4],\n",
       "       [ 5.8,  2.6,  4. ,  1.2],\n",
       "       [ 5. ,  2.3,  3.3,  1. ],\n",
       "       [ 5.6,  2.7,  4.2,  1.3],\n",
       "       [ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 5.7,  2.9,  4.2,  1.3],\n",
       "       [ 6.2,  2.9,  4.3,  1.3],\n",
       "       [ 5.1,  2.5,  3. ,  1.1],\n",
       "       [ 5.7,  2.8,  4.1,  1.3],\n",
       "       [ 6.3,  3.3,  6. ,  2.5],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 7.1,  3. ,  5.9,  2.1],\n",
       "       [ 6.3,  2.9,  5.6,  1.8],\n",
       "       [ 6.5,  3. ,  5.8,  2.2],\n",
       "       [ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 4.9,  2.5,  4.5,  1.7],\n",
       "       [ 7.3,  2.9,  6.3,  1.8],\n",
       "       [ 6.7,  2.5,  5.8,  1.8],\n",
       "       [ 7.2,  3.6,  6.1,  2.5],\n",
       "       [ 6.5,  3.2,  5.1,  2. ],\n",
       "       [ 6.4,  2.7,  5.3,  1.9],\n",
       "       [ 6.8,  3. ,  5.5,  2.1],\n",
       "       [ 5.7,  2.5,  5. ,  2. ],\n",
       "       [ 5.8,  2.8,  5.1,  2.4],\n",
       "       [ 6.4,  3.2,  5.3,  2.3],\n",
       "       [ 6.5,  3. ,  5.5,  1.8],\n",
       "       [ 7.7,  3.8,  6.7,  2.2],\n",
       "       [ 7.7,  2.6,  6.9,  2.3],\n",
       "       [ 6. ,  2.2,  5. ,  1.5],\n",
       "       [ 6.9,  3.2,  5.7,  2.3],\n",
       "       [ 5.6,  2.8,  4.9,  2. ],\n",
       "       [ 7.7,  2.8,  6.7,  2. ],\n",
       "       [ 6.3,  2.7,  4.9,  1.8],\n",
       "       [ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 7.2,  3.2,  6. ,  1.8],\n",
       "       [ 6.2,  2.8,  4.8,  1.8],\n",
       "       [ 6.1,  3. ,  4.9,  1.8],\n",
       "       [ 6.4,  2.8,  5.6,  2.1],\n",
       "       [ 7.2,  3. ,  5.8,  1.6],\n",
       "       [ 7.4,  2.8,  6.1,  1.9],\n",
       "       [ 7.9,  3.8,  6.4,  2. ],\n",
       "       [ 6.4,  2.8,  5.6,  2.2],\n",
       "       [ 6.3,  2.8,  5.1,  1.5],\n",
       "       [ 6.1,  2.6,  5.6,  1.4],\n",
       "       [ 7.7,  3. ,  6.1,  2.3],\n",
       "       [ 6.3,  3.4,  5.6,  2.4],\n",
       "       [ 6.4,  3.1,  5.5,  1.8],\n",
       "       [ 6. ,  3. ,  4.8,  1.8],\n",
       "       [ 6.9,  3.1,  5.4,  2.1],\n",
       "       [ 6.7,  3.1,  5.6,  2.4],\n",
       "       [ 6.9,  3.1,  5.1,  2.3],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 6.8,  3.2,  5.9,  2.3],\n",
       "       [ 6.7,  3.3,  5.7,  2.5],\n",
       "       [ 6.7,  3. ,  5.2,  2.3],\n",
       "       [ 6.3,  2.5,  5. ,  1.9],\n",
       "       [ 6.5,  3. ,  5.2,  2. ],\n",
       "       [ 6.2,  3.4,  5.4,  2.3],\n",
       "       [ 5.9,  3. ,  5.1,  1.8]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_c.create_tensorboard_writer(\"./tensorboard/model_c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_c.write_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_c.write_training_summary(iris_dataset.data, iris_dataset.target, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_c.write_training_summary(iris_dataset.data, iris_dataset.target, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_c.write_training_summary(iris_dataset.data, iris_dataset.target, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_c.tensorboard_writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_c.tensorboard_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_c.session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
